{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from timeit import default_timer\n",
    "import pandas as pd\n",
    "from scipy.linalg import eigh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Data Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_eeg_data(base_path):\n",
    "    \"\"\"Reads .set files from a specified directory and extracts EEG data into a dictionary.\"\"\"\n",
    "    file_paths = glob.glob(os.path.join(base_path, '*.set'))\n",
    "    all_subjects_data = {'Condition1': []}  # Initialize with a single condition name\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        subject_id = os.path.basename(file_path).split('.')[0]\n",
    "        raw = mne.io.read_raw_eeglab(file_path, preload=True)\n",
    "        data = raw.get_data()\n",
    "\n",
    "        # Add data directly to 'Condition1'\n",
    "        all_subjects_data['Condition1'].append(data)\n",
    "\n",
    "    return all_subjects_data\n",
    "\n",
    "\n",
    "\n",
    "def prepare_data_for_cca(all_subjects_data):\n",
    "    \"\"\"Converts the data into the required format (subjects, channels, samples) for each condition.\"\"\"\n",
    "    formatted_data = {}\n",
    "    for condition, data_list in all_subjects_data.items():\n",
    "        num_subjects = len(data_list)\n",
    "        num_channels = data_list[0].shape[0]  # Assuming all data arrays have the same number of channels\n",
    "        num_samples = data_list[0].shape[1]   # Assuming all data arrays have the same number of samples\n",
    "        condition_array = np.empty((num_subjects, num_channels, num_samples))\n",
    "\n",
    "        for i, data in enumerate(data_list):\n",
    "            condition_array[i, :, :] = data\n",
    "\n",
    "        formatted_data[condition] = condition_array\n",
    "        print(f'Formatted data for {condition} has dimensions: {condition_array.shape}')\n",
    "\n",
    "    return formatted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading d:\\Article2\\ICA\\Inter-Subject_Correlation-master\\Data\\T3-1.fdt\n",
      "Reading 0 ... 4864  =      0.000 ...    19.000 secs...\n",
      "Reading d:\\Article2\\ICA\\Inter-Subject_Correlation-master\\Data\\T3-11.fdt\n",
      "Reading 0 ... 4864  =      0.000 ...    19.000 secs...\n",
      "Reading d:\\Article2\\ICA\\Inter-Subject_Correlation-master\\Data\\T3-12.fdt\n",
      "Reading 0 ... 4864  =      0.000 ...    19.000 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22944\\783014707.py:8: RuntimeWarning: Omitted 1 annotation(s) that were outside data range.\n",
      "  raw = mne.io.read_raw_eeglab(file_path, preload=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22944\\783014707.py:8: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_eeglab(file_path, preload=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22944\\783014707.py:8: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(file_path, preload=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22944\\783014707.py:8: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_eeglab(file_path, preload=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22944\\783014707.py:8: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading d:\\Article2\\ICA\\Inter-Subject_Correlation-master\\Data\\T3-13.fdt\n",
      "Reading 0 ... 4864  =      0.000 ...    19.000 secs...\n",
      "Reading d:\\Article2\\ICA\\Inter-Subject_Correlation-master\\Data\\T3-14.fdt\n",
      "Reading 0 ... 4864  =      0.000 ...    19.000 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22944\\783014707.py:8: RuntimeWarning: Omitted 1 annotation(s) that were outside data range.\n",
      "  raw = mne.io.read_raw_eeglab(file_path, preload=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22944\\783014707.py:8: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_eeglab(file_path, preload=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22944\\783014707.py:8: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(file_path, preload=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22944\\783014707.py:8: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_eeglab(file_path, preload=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22944\\783014707.py:8: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading d:\\Article2\\ICA\\Inter-Subject_Correlation-master\\Data\\T3-15.fdt\n",
      "Reading 0 ... 4864  =      0.000 ...    19.000 secs...\n",
      "Reading d:\\Article2\\ICA\\Inter-Subject_Correlation-master\\Data\\T3-2.fdt\n",
      "Reading 0 ... 4864  =      0.000 ...    19.000 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22944\\783014707.py:8: RuntimeWarning: Omitted 1 annotation(s) that were outside data range.\n",
      "  raw = mne.io.read_raw_eeglab(file_path, preload=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22944\\783014707.py:8: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_eeglab(file_path, preload=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22944\\783014707.py:8: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(file_path, preload=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22944\\783014707.py:8: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_eeglab(file_path, preload=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22944\\783014707.py:8: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(file_path, preload=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22944\\783014707.py:8: RuntimeWarning: Omitted 1 annotation(s) that were outside data range.\n",
      "  raw = mne.io.read_raw_eeglab(file_path, preload=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22944\\783014707.py:8: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_eeglab(file_path, preload=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22944\\783014707.py:8: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading d:\\Article2\\ICA\\Inter-Subject_Correlation-master\\Data\\T3-3.fdt\n",
      "Reading 0 ... 4864  =      0.000 ...    19.000 secs...\n",
      "Reading d:\\Article2\\ICA\\Inter-Subject_Correlation-master\\Data\\T3-4.fdt\n",
      "Reading 0 ... 4864  =      0.000 ...    19.000 secs...\n",
      "Reading d:\\Article2\\ICA\\Inter-Subject_Correlation-master\\Data\\T3-5.fdt\n",
      "Reading 0 ... 4864  =      0.000 ...    19.000 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22944\\783014707.py:8: RuntimeWarning: Omitted 1 annotation(s) that were outside data range.\n",
      "  raw = mne.io.read_raw_eeglab(file_path, preload=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22944\\783014707.py:8: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_eeglab(file_path, preload=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22944\\783014707.py:8: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(file_path, preload=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22944\\783014707.py:8: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_eeglab(file_path, preload=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22944\\783014707.py:8: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading d:\\Article2\\ICA\\Inter-Subject_Correlation-master\\Data\\T3-6.fdt\n",
      "Reading 0 ... 4864  =      0.000 ...    19.000 secs...\n",
      "Reading d:\\Article2\\ICA\\Inter-Subject_Correlation-master\\Data\\T3-7.fdt\n",
      "Reading 0 ... 4864  =      0.000 ...    19.000 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22944\\783014707.py:8: RuntimeWarning: Omitted 1 annotation(s) that were outside data range.\n",
      "  raw = mne.io.read_raw_eeglab(file_path, preload=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22944\\783014707.py:8: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_eeglab(file_path, preload=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22944\\783014707.py:8: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(file_path, preload=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22944\\783014707.py:8: RuntimeWarning: Omitted 1 annotation(s) that were outside data range.\n",
      "  raw = mne.io.read_raw_eeglab(file_path, preload=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22944\\783014707.py:8: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_eeglab(file_path, preload=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22944\\783014707.py:8: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(file_path, preload=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22944\\783014707.py:8: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_eeglab(file_path, preload=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22944\\783014707.py:8: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading d:\\Article2\\ICA\\Inter-Subject_Correlation-master\\Data\\T3-8.fdt\n",
      "Reading 0 ... 4864  =      0.000 ...    19.000 secs...\n",
      "Reading d:\\Article2\\ICA\\Inter-Subject_Correlation-master\\Data\\T3-9.fdt\n",
      "Reading 0 ... 4864  =      0.000 ...    19.000 secs...\n",
      "Formatted data for Condition1 has dimensions: (14, 32, 4865)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22944\\783014707.py:8: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_eeglab(file_path, preload=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22944\\783014707.py:8: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(file_path, preload=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22944\\783014707.py:8: RuntimeWarning: Omitted 1 annotation(s) that were outside data range.\n",
      "  raw = mne.io.read_raw_eeglab(file_path, preload=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22944\\783014707.py:8: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_eeglab(file_path, preload=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22944\\783014707.py:8: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(file_path, preload=True)\n"
     ]
    }
   ],
   "source": [
    "# Set the path to the directory containing the EEG data files\n",
    "base_path = './Data'\n",
    "\n",
    "# Read and prepare the EEG data\n",
    "all_subjects_data = read_eeg_data(base_path)\n",
    "formatted_data = prepare_data_for_cca(all_subjects_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data in Condition1 before formatting: [(32, 4865), (32, 4865), (32, 4865), (32, 4865), (32, 4865), (32, 4865), (32, 4865), (32, 4865), (32, 4865), (32, 4865), (32, 4865), (32, 4865), (32, 4865), (32, 4865)]\n",
      "Shape of data in Condition1 after formatting: (14, 32, 4865)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Printing the shape of all_subjects_data and formatted_data\n",
    "for condition, data_list in all_subjects_data.items():\n",
    "    print(f'Shape of data in {condition} before formatting: {[data.shape for data in data_list]}')\n",
    "\n",
    "for condition, data_array in formatted_data.items():\n",
    "    print(f'Shape of data in {condition} after formatting: {data_array.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ایجاد یک دیکشنری جدید با یک شرط واحد 'Condition1'\n",
    "new_formatted_data = {'Condition1': []}\n",
    "\n",
    "# اضافه کردن تمام داده‌ها از شرایط مختلف به 'Condition1'\n",
    "for data_arrays in formatted_data.values():\n",
    "    new_formatted_data['Condition1'].extend(data_arrays)\n",
    "\n",
    "# استفاده از new_formatted_data به جای formatted_data\n",
    "formatted_data = new_formatted_data\n",
    "\n",
    "# چاپ کلیدهای جدید برای تایید تغییر\n",
    "print(\"Updated keys in formatted_data:\", formatted_data.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cca(data):\n",
    "    \"\"\"Run Correlated Component Analysis on your training data.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        data : dict\n",
    "            Dictionary with keys are names of conditions and values are numpy\n",
    "            arrays structured like (subjects, channels, samples).\n",
    "            The number of channels must be the same between all conditions!\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        W : np.array\n",
    "            Columns are spatial filters. They are sorted in descending order, it means that first column-vector maximize\n",
    "            correlation the most.\n",
    "        ISC : np.array\n",
    "            Inter-subject correlation sorted in descending order\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    start = default_timer()\n",
    "\n",
    "    C = len(data.keys())\n",
    "    print(f'train_cca - calculations started. There are {C} conditions')\n",
    "\n",
    "    gamma = 0.1\n",
    "    Rw, Rb = 0, 0\n",
    "    for cond in data.values():\n",
    "        print(data.values())\n",
    "        N, D, T, = cond.shape\n",
    "        print(f'Condition has {N} subjects, {D} sensors and {T} samples')\n",
    "        cond = cond.reshape(D * N, T)\n",
    "\n",
    "        # Rij\n",
    "        Rij = np.swapaxes(np.reshape(np.cov(cond), (N, D, N, D)), 1, 2)\n",
    "\n",
    "        # Rw\n",
    "        Rw = Rw + np.mean([Rij[i, i, :, :]\n",
    "                           for i in range(0, N)], axis=0)\n",
    "\n",
    "        # Rb\n",
    "        Rb = Rb + np.mean([Rij[i, j, :, :]\n",
    "                           for i in range(0, N)\n",
    "                           for j in range(0, N) if i != j], axis=0)\n",
    "\n",
    "    # Divide by number of condition\n",
    "    Rw, Rb = Rw/C, Rb/C\n",
    "\n",
    "    # Regularization\n",
    "    Rw_reg = (1 - gamma) * Rw + gamma * np.mean(eigh(Rw)[0]) * np.identity(Rw.shape[0])\n",
    "\n",
    "    # ISCs and Ws\n",
    "    [ISC, W] = eigh(Rb, Rw_reg)\n",
    "\n",
    "    # Make descending order\n",
    "    ISC, W = ISC[::-1], W[:, ::-1]\n",
    "\n",
    "    stop = default_timer()\n",
    "\n",
    "    print(f'Elapsed time: {round(stop - start)} seconds.')\n",
    "\n",
    "    return W, ISC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cca(data):\n",
    "    from timeit import default_timer\n",
    "    start = default_timer()\n",
    "\n",
    "    C = len(data.keys())\n",
    "    print(f'train_cca - calculations started. There are {C} conditions')\n",
    "\n",
    "    gamma = 0.1\n",
    "    Rw, Rb = 0, 0\n",
    "    for cond in data.values():\n",
    "        N, D, T = cond.shape\n",
    "        print(f'Condition has {N} subjects, {D} sensors and {T} samples')\n",
    "        cond = cond.reshape(D * N, T)\n",
    "\n",
    "        Rij = np.swapaxes(np.reshape(np.cov(cond), (N, D, N, D)), 1, 2)\n",
    "        Rw += np.mean([Rij[i, i, :, :] for i in range(N)], axis=0)\n",
    "        Rb += np.mean([Rij[i, j, :, :] for i in range(N) for j in range(N) if i != j], axis=0)\n",
    "\n",
    "    Rw /= C\n",
    "    Rb /= C\n",
    "\n",
    "    Rw_reg = (1 - gamma) * Rw + gamma * np.mean(np.diag(Rw)) * np.identity(Rw.shape[0])\n",
    "    ISC, W = eigh(Rb, Rw_reg)\n",
    "    ISC, W = ISC[::-1], W[:, ::-1]\n",
    "\n",
    "    stop = default_timer()\n",
    "    print(f'Elapsed time: {round(stop - start)} seconds.')\n",
    "    print(f'Rw and Rb matrices dimensions: {Rw.shape}')\n",
    "    print(f'W matrix dimensions: {W.shape}, ISC dimensions: {ISC.shape}')\n",
    "\n",
    "    return W, ISC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_cca - calculations started. There are 1 conditions\n",
      "Condition has 14 subjects, 32 sensors and 4865 samples\n",
      "Elapsed time: 0 seconds.\n",
      "Rw and Rb matrices dimensions: (32, 32)\n",
      "W matrix dimensions: (32, 32), ISC dimensions: (32,)\n",
      "Spatial Filters (W): [[-63017.10673558  21097.17230384  29687.44787903 ...  52692.94295824\n",
      "   64860.6061318  101643.8529544 ]\n",
      " [-16639.2551861    3092.93862038  25804.94187687 ... -30714.69045219\n",
      "   27850.95945362 -11978.01170203]\n",
      " [ 16299.28047741 -83088.89970116  52514.30917588 ...  25414.63846989\n",
      "   15044.16125389  11195.33885584]\n",
      " ...\n",
      " [-46820.30596577 -57902.76059204 -14275.3651415  ...  54455.70190667\n",
      "  -63213.79977862  75677.2236121 ]\n",
      " [ 19786.75965525  61352.13838495 -67564.97403174 ...  64893.46545812\n",
      "    4542.21987758   8744.65340981]\n",
      " [-23912.83848884 -40778.67160524 105824.15518236 ... -24262.48225599\n",
      "    2634.19836704 -17078.85550077]]\n",
      "Inter-subject Correlations (ISC): [ 0.05380409  0.03706581  0.03427373  0.02820103  0.02461752  0.02108126\n",
      "  0.02003393  0.01836473  0.015223    0.01294234  0.00998887  0.00737464\n",
      "  0.00160655  0.00138641  0.00026516 -0.00122804 -0.00472539 -0.00594109\n",
      " -0.00698163 -0.00878881 -0.00995995 -0.01251244 -0.01292738 -0.01397317\n",
      " -0.01588105 -0.01712861 -0.01842263 -0.02041166 -0.02394306 -0.02493664\n",
      " -0.02833571 -0.03026239]\n"
     ]
    }
   ],
   "source": [
    "# اجرای تابع train_cca با داده‌های آماده شده\n",
    "W, ISC = train_cca(formatted_data)\n",
    "\n",
    "# W و ISC حاوی فیلتر‌های فضایی و همبستگی‌های بین‌فردی هستند که مرتب شده‌اند\n",
    "print(\"Spatial Filters (W):\", W)\n",
    "print(\"Inter-subject Correlations (ISC):\", ISC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ذخیره‌سازی داده‌ها در فایل اکسل\n",
    "df_W = pd.DataFrame(W)\n",
    "df_ISC = pd.DataFrame(ISC)\n",
    "with pd.ExcelWriter('./Data/cca_results.xlsx') as writer:\n",
    "    df_W.to_excel(writer, sheet_name='Spatial_Filters')\n",
    "    df_ISC.to_excel(writer, sheet_name='Inter-subject_Correlations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_cca(X, W, fs):\n",
    "    \"\"\"Applying precomputed spatial filters to your data.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        X : ndarray\n",
    "            3-D numpy array structured like (subject, channel, sample)\n",
    "        W : ndarray\n",
    "            Spatial filters.\n",
    "        fs : int\n",
    "            Frequency sampling.\n",
    "        Returns:\n",
    "        -------\n",
    "        ISC : ndarray\n",
    "            Inter-subject correlations values are sorted in descending order.\n",
    "        ISC_persecond : ndarray\n",
    "            Inter-subject correlations values per second where first row is the most correlated.\n",
    "        ISC_bysubject : ndarray\n",
    "            Description goes here.\n",
    "        A : ndarray\n",
    "            Scalp projections of ISC.\n",
    "    \"\"\"\n",
    "\n",
    "    start = default_timer()\n",
    "    print('apply_cca - calculations started')\n",
    "\n",
    "    N, D, T = X.shape\n",
    "    # gamma = 0.1\n",
    "    window_sec = 5\n",
    "    X = X.reshape(D * N, T)\n",
    "\n",
    "    # Rij\n",
    "    Rij = np.swapaxes(np.reshape(np.cov(X), (N, D, N, D)), 1, 2)\n",
    "\n",
    "    # Rw\n",
    "    Rw = np.mean([Rij[i, i, :, :]\n",
    "                  for i in range(0, N)], axis=0)\n",
    "    # Rw_reg = (1 - gamma) * Rw + gamma * np.mean(eigh(Rw)[0]) * np.identity(Rw.shape[0])\n",
    "\n",
    "    # Rb\n",
    "    Rb = np.mean([Rij[i, j, :, :]\n",
    "                  for i in range(0, N)\n",
    "                  for j in range(0, N) if i != j], axis=0)\n",
    "\n",
    "    # ISCs\n",
    "    ISC = np.sort(np.diag(np.transpose(W) @ Rb @ W) / np.diag(np.transpose(W) @ Rw @ W))[::-1]\n",
    "\n",
    "    # Scalp projections\n",
    "    A = np.linalg.solve(Rw @ W, np.transpose(W) @ Rw @ W)\n",
    "\n",
    "    # ISC by subject\n",
    "    print('by subject is calculating')\n",
    "    ISC_bysubject = np.empty((D, N))\n",
    "\n",
    "    for subj_k in range(0, N):\n",
    "        Rw, Rb = 0, 0\n",
    "        Rw = np.mean([Rw + 1 / (N - 1) * (Rij[subj_k, subj_k, :, :] + Rij[subj_l, subj_l, :, :])\n",
    "                      for subj_l in range(0, N) if subj_k != subj_l], axis=0)\n",
    "        Rb = np.mean([Rb + 1 / (N - 1) * (Rij[subj_k, subj_l, :, :] + Rij[subj_l, subj_k, :, :])\n",
    "                      for subj_l in range(0, N) if subj_k != subj_l], axis=0)\n",
    "\n",
    "        ISC_bysubject[:, subj_k] = np.diag(np.transpose(W) @ Rb @ W) / np.diag(np.transpose(W) @ Rw @ W)\n",
    "\n",
    "    # ISC per second\n",
    "    print('by persecond is calculating')\n",
    "    ISC_persecond = np.empty((D, int(T / fs) + 1))\n",
    "    window_i = 0\n",
    "\n",
    "    for t in range(0, T, fs):\n",
    "\n",
    "        Xt = X[:, t:t+window_sec*fs]\n",
    "        Rij = np.cov(Xt)\n",
    "        Rw = np.mean([Rij[i:i + D, i:i + D]\n",
    "                      for i in range(0, D * N, D)], axis=0)\n",
    "        Rb = np.mean([Rij[i:i + D, j:j + D]\n",
    "                      for i in range(0, D * N, D)\n",
    "                      for j in range(0, D * N, D) if i != j], axis=0)\n",
    "\n",
    "        ISC_persecond[:, window_i] = np.diag(np.transpose(W) @ Rb @ W) / np.diag(np.transpose(W) @ Rw @ W)\n",
    "        window_i += 1\n",
    "\n",
    "    stop = default_timer()\n",
    "    print(f'Elapsed time: {round(stop - start)} seconds.')\n",
    "\n",
    "    return ISC, ISC_persecond, ISC_bysubject, A\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_for_apply_cca(data_dict, condition):\n",
    "    \"\"\"\n",
    "    Converts data from the dictionary format used in train_cca to the ndarray format required for apply_cca.\n",
    "    \n",
    "    Parameters:\n",
    "    data_dict (dict): Dictionary containing condition data where each key is a condition\n",
    "                      and each value is a 3D ndarray (subjects, channels, samples).\n",
    "    condition (str): The condition key for which data is to be extracted and converted.\n",
    "\n",
    "    Returns:\n",
    "    ndarray: A 3D numpy array of the format (subjects, channels, samples) suitable for use in apply_cca.\n",
    "    \"\"\"\n",
    "    if condition not in data_dict:\n",
    "        raise ValueError(f\"No data available for the condition '{condition}'\")\n",
    "\n",
    "    # Extracting data for the specific condition\n",
    "    data_array = data_dict[condition]\n",
    "    \n",
    "    # Ensure the data is in the correct format\n",
    "    if not isinstance(data_array, np.ndarray) or data_array.ndim != 3:\n",
    "        raise ValueError(\"Data format is incorrect. It should be a 3D numpy array.\")\n",
    "\n",
    "    return data_array\n",
    "\n",
    "# Assuming 'formatted_data' is your dictionary from train_cca that has been populated correctly\n",
    "condition_key = 'Condition1'  # Adjusted key to 'Condition1' based on your specification\n",
    "try:\n",
    "    X = convert_for_apply_cca(formatted_data, condition_key)\n",
    "    print(\"Data is ready for apply_cca.\")\n",
    "    # Assuming W and fs are defined properly from your previous outputs or setups\n",
    "    ISC, ISC_persecond, ISC_bysubject, A = apply_cca(X, W, 256)  # Assuming fs=256 Hz as sampling frequency\n",
    "\n",
    "    # Output results for verification\n",
    "    print(\"Inter-subject correlations (ISC):\", ISC)\n",
    "    print(\"Inter-subject correlations per second (ISC_persecond):\", ISC_persecond)\n",
    "    print(\"Inter-subject correlations by subject (ISC_bysubject):\", ISC_bysubject)\n",
    "    print(\"Scalp projections of ISC (A):\", A)\n",
    "\n",
    "except ValueError as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer\n",
    "\n",
    "import numpy as np\n",
    "import numpy.matlib as npm\n",
    "\n",
    "\n",
    "def shuffle_in_time(data, window, fs):\n",
    "    \"\"\"Splits the time series and shuffle the order of splits.\n",
    "\n",
    "        Parameters:\n",
    "        -------\n",
    "        data : dict\n",
    "            Dictionary with keys are names of conditions and values are\n",
    "            numpy arrays structured like (subjects, channels, samples).\n",
    "        window : int\n",
    "            The length of one split.\n",
    "        fs : int\n",
    "            Frequency sampling.\n",
    "        Returns:\n",
    "        -------\n",
    "        data_shuffled : dict\n",
    "            Shuffled data with the same structure as data.\n",
    "    \"\"\"\n",
    "    data_shuffled = dict()\n",
    "\n",
    "    for cond, values in data.items():\n",
    "        cond_shuffled = np.zeros(values.shape)\n",
    "        n_samples = values[0].shape[1]\n",
    "        n_splits = n_samples/fs/window\n",
    "\n",
    "        for subj_i, subj in enumerate(values):\n",
    "            for ch_i, ch in enumerate(subj):\n",
    "                splitted = np.array_split(ch, n_splits)\n",
    "                np.random.shuffle(splitted)\n",
    "                ch_shuffled = np.concatenate(splitted)\n",
    "                cond_shuffled[subj_i, ch_i, :] = ch_shuffled\n",
    "\n",
    "        data_shuffled[str(cond)] = cond_shuffled\n",
    "\n",
    "    return data_shuffled\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# فرض بر اینکه 'formatted_data' داده‌های ما به فرمت درست دیکشنری با کلیدهای شرایط است\n",
    "condition_key = 'Condition1'  # کلید موجود بر اساس داده‌هایی که داریم\n",
    "try:\n",
    "    # استخراج داده برای شرط مورد نظر\n",
    "    data_for_shuffling = {condition_key: formatted_data[condition_key]}\n",
    "\n",
    "    # مقادیر ورودی برای تابع shuffle_in_time\n",
    "    window = 10  # مثلاً طول هر بخش بر حسب ثانیه\n",
    "    fs = 256  # فرکانس نمونه‌برداری بر حسب هرتز\n",
    "\n",
    "    # فراخوانی تابع shuffle_in_time\n",
    "    shuffled_data = shuffle_in_time(data_for_shuffling, window, fs)\n",
    "\n",
    "    # چاپ نتایج برای بررسی\n",
    "    print(\"Shuffled data is ready.\")\n",
    "except ValueError as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def phase_randomized(X):\n",
    "    \"\"\"Calculates phase randomized data based on real data. The full algorithm is described here Pritchard 1991.\n",
    "\n",
    "        Parameters:\n",
    "        -------\n",
    "        X : ndarray\n",
    "            3-D numpy array structured like (subject, channel, sample)\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        Xr : ndarray\n",
    "            3-D numpy array structured like (subject, channel, sample) with random phase added\n",
    "    \"\"\"\n",
    "    start = default_timer()\n",
    "\n",
    "    N, D, T = X.shape\n",
    "    print(f'\\n{N} subjects, {D} sensors and {T} samples')\n",
    "\n",
    "    Xr = np.empty((N, D, T))\n",
    "\n",
    "    for subject in range(0, N):\n",
    "\n",
    "        Xfft = np.fft.rfft(X[subject, :, :], T)\n",
    "        ampl = np.abs(Xfft)\n",
    "        phi = np.angle(Xfft)\n",
    "        # np.random.seed(42)\n",
    "        phi_r = 4 * np.arccos(0) * np.random.rand(1, int(T / 2 - 1)) - 2 * np.arccos(0)\n",
    "        Xfft[:, 1:int(T / 2)] = ampl[:, 1:int(T / 2)] * np.exp(\n",
    "            np.sqrt(-1 + 0j) * (phi[:, 1:int(T / 2)] + npm.repmat(phi_r, D, 1)))\n",
    "        Xr[subject, :, :] = np.fft.irfft(Xfft, T)\n",
    "\n",
    "    stop = default_timer()\n",
    "    print(f'Elapsed time: {round(stop - start)} seconds.')\n",
    "\n",
    "    return Xr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# فرض بر اینکه 'formatted_data' داده‌های ما به فرمت درست دیکشنری با کلیدهای شرایط است\n",
    "condition_key = 'Condition1'  # کلید موجود بر اساس داده‌هایی که داریم\n",
    "try:\n",
    "    # استخراج داده برای شرط مورد نظر\n",
    "    X = formatted_data[condition_key]\n",
    "\n",
    "    if not isinstance(X, np.ndarray) or X.ndim != 3:\n",
    "        raise ValueError(\"Data format is incorrect. It should be a 3D numpy array.\")\n",
    "\n",
    "    print(\"Data is ready for phase randomization.\")\n",
    "    # فراخوانی تابع phase_randomized\n",
    "    Xr = phase_randomized(X)\n",
    "\n",
    "    # چاپ نتایج برای بررسی\n",
    "    print(\"Phase-randomized data is prepared.\")\n",
    "\n",
    "except ValueError as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_isc(isc_all):\n",
    "    # plot ISC as a bar chart\n",
    "    plt.figure()\n",
    "    comp1 = [cond['ISC'][0] for cond in isc_all.values()]\n",
    "    comp2 = [cond['ISC'][1] for cond in isc_all.values()]\n",
    "    comp3 = [cond['ISC'][2] for cond in isc_all.values()]\n",
    "    barWidth = 0.2\n",
    "    r1 = np.arange(len(comp1))\n",
    "    r2 = [x + barWidth for x in r1]\n",
    "    r3 = [x + barWidth for x in r2]\n",
    "    plt.bar(r1, comp1, color='gray', width=barWidth, edgecolor='white', label='Comp1')\n",
    "    plt.bar(r2, comp2, color='green', width=barWidth, edgecolor='white', label='Comp2')\n",
    "    plt.bar(r3, comp3, color='green', width=barWidth, edgecolor='white', label='Comp3')\n",
    "    plt.xticks([r + barWidth for r in range(len(comp1))], isc_all.keys())\n",
    "    plt.ylabel('ISC', fontweight='bold')\n",
    "    plt.title('ISC for each condition')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # plot ISC_persecond\n",
    "    plt.figure()\n",
    "    for cond in isc_all.values():\n",
    "        for comp_i in range(0, 3):\n",
    "            plt.subplot(3, 1, comp_i+1)\n",
    "            plt.plot(cond['ISC_persecond'][comp_i][:-2])\n",
    "            plt.legend(isc_all.keys())\n",
    "            plt.xlabel('Time (s)')\n",
    "            plt.ylabel('ISC')\n",
    "            plt.title('ISC per second for each condition')\n",
    "\n",
    "    # plot ISC_bysubject\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title('ISC by subject for each condition')\n",
    "    a = [cond['ISC_bysubject'][0, :] for cond in isc_all.values()]\n",
    "    ax.set_xticklabels(isc_all.keys())\n",
    "    ax.set_ylabel('ISC')\n",
    "    ax.set_xlabel('Conditions', fontweight='bold')\n",
    "    ax.boxplot(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isc_all = {\n",
    "    'Condition1': {\n",
    "        'ISC': ISC,\n",
    "        'ISC_persecond': ISC_persecond,\n",
    "        'ISC_bysubject': ISC_bysubject\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_isc(isc_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
